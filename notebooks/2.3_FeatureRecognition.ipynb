{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.3_FeatureRecognition.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mFQ2JNZn8oIm"},"source":["<img src=https://brand.uark.edu/_resources/images/UA_Logo_Horizontal.jpg width=\"400\" height=\"96\">\n","\n","###_Artificial intelligence for image processing and analysis._"]},{"cell_type":"markdown","metadata":{"id":"8g_Y-BQS8vsu"},"source":["# Notebook 2.3 Feature Recognition\n","---\n","##### The purpose of this notebook is showcase how we can pull out some feature within an image, and use that to identify where that feature is in an image.\n","##### For image processing, another useful thing that we can do with image convolution is detect _features_, or _patterns_ within an image. To determine where a specific _feature_ is in an image, we can convolve the image with that particular feature.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"44Kj2s6vPtIm"},"source":["### Required packages\n","---\n","##### **_Run this code chunk first. If you encounter an error when trying to run code chunks in this notebook, then first try re-running this chunk._**"]},{"cell_type":"code","metadata":{"id":"hq84n-cRL-aP"},"source":["# Import all of the necessary packages\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import imageio as io\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4RudU1qsjQOa"},"source":["# Edge Detection\n","---\n","##### Sometimes, it is useful to determine in code where an object in the foreground is, compared to a background. For this type of analysis, one approach is to determine where the edge of the foreground object is, which can then be used to determine an objects location. \n","##### The edges of an object can be determined with a special _[Sobel](https://en.wikipedia.org/wiki/Sobel_operator) filter_. This type of filter is used to highlight sharp changes in intensity in the image (occurring over the span of a few pixels), which can be interpreted as an edge. By doing this in two dimensions, all of the edges in an image can be highlighted.\n","##### In the following example, a _sobel filter_ is used to determine where the coins in the image are, relative to the background."]},{"cell_type":"code","metadata":{"id":"q-RADHFRpgUg"},"source":["# Load an example image\n","test_image = io.imread(\"imageio:coins.png\") / 255\n","\n","# Generate 2D Sobel filters\n","x_gradient = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])\n","y_gradient = x_gradient.T\n","\n","# Get the two intensity gradients\n","torch_image = torch.tensor(test_image).unsqueeze(0).unsqueeze(1).float()\n","torch_x_gradient = torch.tensor(x_gradient).unsqueeze(0).unsqueeze(1).float()\n","torch_y_gradient = torch.tensor(y_gradient).unsqueeze(0).unsqueeze(1).float()\n","\n","image_x = torch.nn.functional.conv2d(torch_image,torch_x_gradient).squeeze()\n","image_y = torch.nn.functional.conv2d(torch_image,torch_y_gradient).squeeze()\n","edges = torch.sqrt((image_x**2) + (image_y**2))\n","\n","# Display the...\n","fig = plt.figure(figsize=(15,15))\n","\n","# Initial Image\n","ax = fig.add_subplot(2, 2, 1)\n","ax.set_title('Initial Image')\n","plot1 = plt.imshow(test_image,cmap='gray')\n","\n","# X Gradient\n","ax = fig.add_subplot(2, 2, 2)\n","ax.set_title('Edges in X-Direction. Imagine a light shining from left to right.')\n","plot2 = plt.imshow(image_x,cmap='gray')\n","\n","# Y Gradient\n","ax = fig.add_subplot(2, 2, 3)\n","ax.set_title('Edges in Y-Direction. Imagine a light shining from top to bottom.')\n","plot3 = plt.imshow(image_y,cmap='gray')\n","\n","# All edges\n","ax = fig.add_subplot(2,2,4)\n","ax.set_title('All edges are highlighted. Notice how the outlines of all coins are highlighted.')\n","plot4 = plt.imshow(edges,cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7at981ehhLmi"},"source":["# Text Analysis\n","---\n","##### By convolving an image with an example of the letter (or letters) that you want to pick out, you can find where that letter is in an image.\n","##### Here is an example image of some text:\n","<img src=\"https://raw.githubusercontent.com/imageio/imageio-binaries/master/images/page.png\">\n","\n","##### In the following example, a letter is picked out within the text, and used to determine where the same letter is in the entire text. Keep in mind that this is not perfect, but works relatively well."]},{"cell_type":"code","metadata":{"id":"MUsTxFk5gqob","cellView":"form"},"source":["# Load an example image\n","test_image = io.imread(\"imageio:page.png\") / 255\n","\n","# Include form to letter to identify\n","# --- Form starts here --- #\n","#@title Choose a letter to identify within the image { run: \"auto\" }\n","letter = \"e\" #@param [\"s\",\"e\",\"a\"]\n","# --- Form ends here --- #\n","\n","if letter == 's':\n","  kernel_size = (9,9)\n","  image_feature = test_image[72:72+kernel_size[0],251:251+kernel_size[1]]\n","  thr = 0.72\n","elif letter == 'e':\n","  kernel_size = (9,9)\n","  image_feature = test_image[108:108+kernel_size[0],287:287+kernel_size[1]]\n","  thr = 0.71\n","elif letter == 'a':\n","  kernel_size = (9,9)\n","  image_feature = test_image[106:106+kernel_size[0],88:88+kernel_size[1]]\n","  thr = 0.75\n","\n","# Display the...\n","fig = plt.figure(figsize=(1,1))\n","\n","# Letter\n","ax = fig.gca()\n","ax.set_title('Chosen letter')\n","plot1 = plt.imshow(image_feature,cmap='gray')\n","\n","# Do some magic to the letter\n","image_feature = (image_feature - np.mean(image_feature)) / np.std(image_feature)\n","image_feature = np.conj(image_feature)\n","\n","# Do some magic to the input image\n","test_image -= np.mean(test_image)\n","test_image = np.pad(test_image,(kernel_size[0]//2,kernel_size[1]//2))\n","corr_image = np.zeros(test_image.shape)\n","\n","# Go through each pixel and see if the letter is contained there\n","for i in range(kernel_size[0]//2,corr_image.shape[0]-kernel_size[0]//2):\n","  for j in range(kernel_size[1]//2,corr_image.shape[1]-kernel_size[1]//2):\n","    roi = test_image[i-kernel_size[0]//2:i+kernel_size[0]//2+1,j-kernel_size[1]//2:j+kernel_size[1]//2+1]\n","    if np.std(roi) != 0: \n","      roi = (roi - np.mean(roi)) / np.std(roi)\n","    else:\n","      roi = np.zeros(roi.shape)\n","\n","    corr_image[i-kernel_size[0]//2,j-kernel_size[1]//2] = np.sum(image_feature * roi) / (kernel_size[0]*kernel_size[1])\n","\n","corr_image[corr_image<0] = 0\n","\n","# Find all of the places where the letter is\n","y,x = np.where(corr_image>thr)\n","\n","# Show where the letters were found\n","fig = plt.figure(figsize=(13.5,13.5))\n","ax = plt.gca()\n","ax.set_title(\"Estimated locations of letter in the image\")\n","im = plt.imshow(test_image,cmap='gray')\n","sc = plt.scatter(x+5,y+5,s=500,facecolor=[],edgecolor='r',marker='o')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JyVY0iezixs"},"source":["# Biomedical image feature recognition\n","---\n","##### It can also be very helpful to highlight certain features within an image, which can be done be convolving the image with a small feature that is pulled out from the image.\n","##### Here is a common biomedical image containing a mixture of cells, including many circular red blood cells:\n","<img src=\"https://github.com/aewoessn/outreach-program-2021/blob/main/images/red_blood_cells_small.png?raw=true\" alt=\"red_blood_cells_small.png\" width=\"400\" height=\"287\">\n","\n","##### For this particular task, we will only be using a greyscale version of this image:\n","<img src=\"https://github.com/aewoessn/outreach-program-2021/blob/main/images/red_blood_cells_small_grey.png?raw=true\" alt=\"red_blood_cells_small.png\" width=\"400\" height=\"287\">\n","\n","##### In the following code chunk, we pull out a single blood cell from the image, and convolve that with the entire image to locate cells within the image."]},{"cell_type":"code","metadata":{"id":"hbqbpHiGzr-5"},"source":["# Load red blood cell image from github\n","url = \"https://github.com/aewoessn/outreach-program-2021/blob/main/images/red_blood_cells_small.png?raw=true\"\n","test_image = np.mean(io.imread(url),axis=2) / 255\n","\n","# Isolate a single red blood cell\n","kernel_size = (41,41)\n","image_feature = test_image[310:310+kernel_size[0],209:209+kernel_size[1]]\n","\n","# Display the...\n","fig = plt.figure(figsize=(1,1))\n","\n","# Image feature\n","ax = fig.gca()\n","ax.set_title('Single red blood cell feature')\n","plot1 = plt.imshow(image_feature,cmap='gray')\n","\n","image_feature = (image_feature - np.mean(image_feature)) / np.std(image_feature)\n","image_feature = np.conj(image_feature)\n","\n","test_image -= np.mean(test_image)\n","test_image = np.pad(test_image,(kernel_size[0]//2,kernel_size[1]//2))\n","corr_image = np.zeros(test_image.shape)\n","\n","for i in range(kernel_size[0]//2,corr_image.shape[0]-kernel_size[0]//2):\n","  for j in range(kernel_size[1]//2,corr_image.shape[1]-kernel_size[1]//2):\n","    roi = test_image[i-kernel_size[0]//2:i+kernel_size[0]//2+1,j-kernel_size[1]//2:j+kernel_size[1]//2+1]\n","    if np.std(roi) != 0: \n","      roi = (roi - np.mean(roi)) / np.std(roi)\n","    else:\n","      roi = np.zeros(roi.shape)\n","\n","    corr_image[i-kernel_size[0]//2,j-kernel_size[1]//2] = np.sum(image_feature * roi) / (kernel_size[0]*kernel_size[1])\n","\n","corr_image[corr_image<0] = 0\n","thr = 0.7\n","\n","# Find all of the places where the letter is\n","y,x = np.where(corr_image>thr)\n","\n","# Show where the letters were found\n","fig = plt.figure(figsize=(13.5,13.5))\n","ax = plt.gca()\n","ax.set_title(\"Estimated locations of red blood cells in the image\")\n","im = plt.imshow(test_image,cmap='gray')\n","sc = plt.scatter(x+21,y+21,s=500,facecolor=[],edgecolor='r',marker='o')"],"execution_count":null,"outputs":[]}]}