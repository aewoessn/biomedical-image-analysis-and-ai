{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.2_CNNCompetition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFQ2JNZn8oIm"
      },
      "source": [
        "<img src=https://brand.uark.edu/_resources/images/UA_Logo_Horizontal.jpg width=\"400\" height=\"96\">\n",
        "\n",
        "###_Biomedical Image Analysis & Artificial Intelligence_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g_Y-BQS8vsu"
      },
      "source": [
        "# Notebook 4.2 CNN Competition\n",
        "---\n",
        "##### The purpose of this notebook is to set up a competition using convolutional neural networks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Kj2s6vPtIm"
      },
      "source": [
        "### Required packages\n",
        "---\n",
        "##### **_NOTE: This notebook will require the use of GPU hardware acceleration. please refer to notebook 2.4_ParallelProcessing if you need  refresher on how to do this._**\n",
        "##### **_Run this code chunk first. If you encounter an error when trying to run code chunks in this notebook, then first try re-running this chunk._**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq84n-cRL-aP"
      },
      "source": [
        "# Import all of the necessary packages\n",
        "import numpy as np\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import time\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets as widgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xiz3td-wGo2v"
      },
      "source": [
        "# Faces dataset\n",
        "---\n",
        "##### The following code chunks need to be run to define the dataset class and download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLj_AOqejkpx"
      },
      "source": [
        "class UTKFaceDataset(torch.utils.data.Dataset):\n",
        "  # Define what will be ran at initialization of the UTKFaceDataset class\n",
        "  def __init__(self, image_array, age_array):\n",
        "    # Attach the list of images and ages to the class\n",
        "    # These are attached to the class so that they can be accessed by other methods in the class\n",
        "    self.images = image_array\n",
        "    self.ages = age_array\n",
        "\n",
        "    # Initialize a transform that will be used later\n",
        "    self.tform = T.ToTensor()                       \n",
        "\n",
        "  # There are two required methods for a class that inherits from torch.utils.data.Dataset:\n",
        "  # __len__()\n",
        "  # __getitem__()\n",
        "\n",
        "  # Return the length of the dataset\n",
        "  def __len__(self):\n",
        "    return len(self.ages)\n",
        "\n",
        "  # Return a single image from the dataset, as well as the age associated with the image\n",
        "  def __getitem__(self,idx):\n",
        "    # Return a single variable (dict) that contains both the image and the age\n",
        "    out = {\n",
        "        'image': self.tform(self.images[:,:,idx]).float(),\n",
        "        'age': torch.tensor(self.ages[idx]).float()\n",
        "    }\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVp7d8R13d0"
      },
      "source": [
        "import os\n",
        "\n",
        "# Check to see if file exists\n",
        "filename = \"/content/age_gender.csv\"\n",
        "if not os.path.isfile(filename):\n",
        "  # If it does not, then download it\n",
        "  !gdown --id 1IqVy6z09vymy4KJb4AcJtV3Q5hnyFLFB\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "# Move important information out of the data variable since pandas does not like to hold on to information like...\n",
        " \n",
        "# Age of people in images\n",
        "data_ages = np.expand_dims(np.array(data['age']),1) / 1.\n",
        "\n",
        "# Images of people\n",
        "print('Breaking up dataset...')\n",
        "data_images = np.zeros((48,48,len(data)))\n",
        "for i in range(len(data)):\n",
        "  data_images[:,:,i] = np.array(data['pixels'][i].split(),'float64').reshape(48,48) / 255.\n",
        "print('...Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lGnOv0Kqb68"
      },
      "source": [
        "# Deep learning competition\n",
        "---\n",
        "##### In the next portion of this notebook, we propose a challenge for you to modify a CNN to get the lowest training time and the most accurate network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RRJceeiDzMd"
      },
      "source": [
        "### Adjusting hyperparameters\n",
        "---\n",
        "##### The code chunk below has forms that can be modified to change the architecture of the network used to predict the age of the faces in the images. \n",
        "##### When you are done modifying the network architecture (this can be done however many times you want), then pressing the \"Verify model\" will estimate how long it will take to train the model. **_Please keep note that the training time must stay under 20 minutes to qualify for the competition._**\n",
        "##### To give you an idea on if your network is doing well or not, here is the report generated from a network trained with all of the default settings:\n",
        "```\n",
        "Number of convolution filters: 3\n",
        "Number of filters in convolution layers: [128, 64, 32]\n",
        "Size of filters: [3, 3, 3]\n",
        "Number of connections in MLP: [512, 256, 64]\n",
        "Number of epochs: 20\n",
        "Time it took to train: 7.41883\n",
        "Prediction error: 8.47295\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCxF623g4vdF"
      },
      "source": [
        "#### Convolutional layers\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v88vFrqrx3HL",
        "cellView": "form"
      },
      "source": [
        "# Generate a model\n",
        "#@title Number of convolution layers? (at least 1) {run: \"auto\"}\n",
        "number_of_conv_layers =  3#@param {type:\"integer\"}\n",
        "number_of_conv_layers = max(number_of_conv_layers,1)\n",
        "\n",
        "style = {'description_width': 'initial'}\n",
        "default_filters = [128,64,32]\n",
        "if number_of_conv_layers > 3:\n",
        "  for i in range(3,number_of_conv_layers):\n",
        "    default_filters.append(1)\n",
        "default_size = []\n",
        "for i in range(number_of_conv_layers):\n",
        "  default_size.append(3)\n",
        "\n",
        "conv_layers = widgets.GridspecLayout(number_of_conv_layers, 2, width='600px')\n",
        "for i in range(number_of_conv_layers):\n",
        "        conv_layers[i, 0] = widgets.IntText(value=default_filters[i],description='Filters in conv layer '+str(i+1)+':',layout=widgets.Layout(width='70%'),style=style)\n",
        "        conv_layers[i, 1] = widgets.IntText(value=default_size[i],description='Size of filter in layer '+str(i+1)+':',layout=widgets.Layout(width='70%'),style=style)\n",
        "display(conv_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DVjSdH43j4"
      },
      "source": [
        "#### Multi-layer perceptron \n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "0cxTHHdU6Fc-"
      },
      "source": [
        "#@title Number of MLP layers? (at least 1, excluding the output layer) {run: \"auto\"}\n",
        "number_of_mlp_layers =  3#@param {type:\"integer\"}\n",
        "number_of_mlp_layers = max(number_of_mlp_layers,1)\n",
        "\n",
        "style = {'description_width': 'initial'}\n",
        "default_connections = [512,256,64]\n",
        "if number_of_mlp_layers > 3:\n",
        "  for i in range(3,number_of_mlp_layers):\n",
        "    default_connections.append(1)\n",
        "\n",
        "mlp_layers = widgets.GridspecLayout(number_of_conv_layers, 1, width='600px')\n",
        "for i in range(number_of_conv_layers):\n",
        "        mlp_layers[i, 0] = widgets.IntText(value=default_connections[i],description='Inputs for MLP layer '+str(i+1)+':',layout=widgets.Layout(width='35%'),style=style)\n",
        "display(mlp_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0OOqZVk7kOm"
      },
      "source": [
        "#### Training amount\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UHeVpfU7ob-",
        "cellView": "form"
      },
      "source": [
        "#@title Number of training epochs? {run: \"auto\"}\n",
        "number_of_epochs =  20 #@param {type:\"integer\"}\n",
        "number_of_epochs = max(number_of_epochs,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkvJL42q7Uv1"
      },
      "source": [
        "#### Verifying network\n",
        "---\n",
        "##### When you have set up your network parameters, then run the next code chunk and click the \"Verify model\" button. This will double check the selected network parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqHgGwbJ88_3",
        "cellView": "form"
      },
      "source": [
        "#@title --- Hidden code (double-click to show code) ---\n",
        "# Internal functions that will be used\n",
        "def create_network(conv_layers,mlp_layers):\n",
        "  modules = []\n",
        "  img_size = 48\n",
        "  current_channels = 1\n",
        "  \n",
        "  # Generate convolutional, relu, max pool, and batch norm layers\n",
        "  count = 0\n",
        "  for i in range(conv_layers.n_rows):\n",
        "    number_of_filters = conv_layers.children[count].value\n",
        "    size_of_filters = conv_layers.children[count+1].value\n",
        "    max_pool_size = 2\n",
        "    count += 2\n",
        "    modules.append(nn.Conv2d(current_channels,number_of_filters,size_of_filters))\n",
        "    modules.append(nn.ReLU())\n",
        "    modules.append(nn.MaxPool2d(max_pool_size))\n",
        "    modules.append(nn.BatchNorm2d(number_of_filters))\n",
        "\n",
        "    current_channels = number_of_filters\n",
        "    img_size -= ((size_of_filters//2) * 2)\n",
        "    img_size //= 2\n",
        "\n",
        "  # Add on flatten layer\n",
        "  modules.append(nn.Flatten(start_dim=1,end_dim=-1))\n",
        "  current_input = (img_size**2) * current_channels\n",
        "  \n",
        "  # Add MLP layers\n",
        "  for i in range(mlp_layers.n_rows):\n",
        "    number_of_connections = mlp_layers.children[i].value\n",
        "    modules.append(nn.Linear(int(current_input),number_of_connections))\n",
        "    modules.append(nn.ReLU())\n",
        "\n",
        "    current_input = number_of_connections\n",
        "\n",
        "  # Add output\n",
        "  modules.append(nn.Linear(current_input,1))\n",
        "\n",
        "  # Convert list to network\n",
        "  temp_model = nn.Sequential(*modules)\n",
        "\n",
        "  return temp_model\n",
        "\n",
        "def verify_model(b):\n",
        "  # Generate the model\n",
        "  b.disabled = True\n",
        "  print('Generating model...')\n",
        "  temp_model = create_network(conv_layers,mlp_layers)\n",
        "\n",
        "  # Try to attach the network to a GPU\n",
        "  try:\n",
        "    temp_model = temp_model.cuda()\n",
        "    canUseGPU = True\n",
        "  except:\n",
        "    print('Warning: The GPU has not been enabled. Training may take longer than expected.')\n",
        "    canUseGPU = False\n",
        "  print('...Done')\n",
        "\n",
        "  # Time how long it takes to complete a batch of images\n",
        "  print('Setting up dataset...')\n",
        "  dataset = UTKFaceDataset(data_images,data_ages)\n",
        "  train_dataloader = torch.utils.data.DataLoader(dataset=dataset, shuffle=True, batch_size=batchsize)\n",
        "  loss = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(temp_model.parameters())\n",
        "  print('...Done')\n",
        "\n",
        "  # Estimate the time it will take to train the model by running a batch of the training set 5 times and then averaging\n",
        "  print('Timing model...')\n",
        "  est_time = []\n",
        "  for i in range(5):\n",
        "    # Start the timer\n",
        "    begin_time = time.time()\n",
        "\n",
        "    # Run the training batch\n",
        "    dataiter = iter(train_dataloader)\n",
        "    batch = dataiter.next()\n",
        "\n",
        "    # Move things to GPU\n",
        "    if canUseGPU:\n",
        "      batch['image'] = batch['image'].cuda()\n",
        "      batch['age'] = batch['age'].cuda()\n",
        "\n",
        "    # Do typical training loop things\n",
        "    output = temp_model.forward(batch['image'])\n",
        "    loss_value = loss(output,batch['age'])\n",
        "    loss_value.backward()\n",
        "    optimizer.step() \n",
        "\n",
        "    # Stop the timer and add the elapsed time to a variable\n",
        "    end_time = time.time()\n",
        "    est_time.append((end_time - begin_time) * 1.5 * ((18964//batchsize)+1))\n",
        "    print('...')\n",
        "\n",
        "  # Average the time estiamted for an epoch\n",
        "  est_time_tensor = torch.tensor(est_time)\n",
        "  est_time_tensor = torch.mean(est_time_tensor[2:-1])\n",
        "  est_ep_time = est_time_tensor.item()\n",
        "\n",
        "  # Use that to estimate how long it will take to train\n",
        "  est_train_time = round((((est_ep_time) * (number_of_epochs+1)) / 60),ndigits=2)\n",
        "  print('...Done')\n",
        "\n",
        "  # Print the results\n",
        "  print('Estimated epoch time: ' + str(est_ep_time) + ' seconds.')\n",
        "  print('Estimated training time: ' + str(est_train_time) + ' minutes.' )\n",
        "  if est_train_time > 15:\n",
        "    print('WARNING: Your estimated training time is high. You may want to consider decreasing some hyperparameters.')\n",
        "  b.disabled = False\n",
        "\n",
        "# Actual code\n",
        "# Fixed parameters\n",
        "batchsize = 10\n",
        "\n",
        "# Add in button for verifying model\n",
        "verify_button = widgets.Button(description=\"Verify model\")\n",
        "output = widgets.Output()\n",
        "display(verify_button,output)\n",
        "\n",
        "# Set up callback\n",
        "verify_button.on_click(verify_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHyxvCEvGfNU"
      },
      "source": [
        "### Training the model\n",
        "---\n",
        "##### A required practice for training any type of AI is to break up the entire dataset you want to train the model on into a _training_, _validation_, and _testing_ set. \n",
        "##### The _training_ set is used to actually train the model, and usually is approximately 70% to 80% of the whole dataset.\n",
        "##### That amount of the dataset that is left over typically gets halved, where one half, the _validation_ set, gets used to make sure that the model is not memorizing the _training_ set. Keep in mind that the model is **_not_** trained on.\n",
        "##### The rest of the dataset gets lumped into the _testing_ set, which is used after the training has been completed to test the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al7CRYn3yR1A",
        "cellView": "form"
      },
      "source": [
        "#@title --- Hidden code (double-click to show code) ---\n",
        "# Define method for updating plot\n",
        "def update_plots(ep_range,train_history,valid_history):\n",
        "  clear_output(wait=True)\n",
        "  if not canUseGPU:\n",
        "    print('Warning: The GPU has not been enabled. Training may take longer than expected.')\n",
        "\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax1 = fig.add_subplot(2,1,1)\n",
        "  plt1 = plt.plot(ep_range,train_history,'ro-')\n",
        "  ax1.set_title('Average training loss');\n",
        "  ax1.set_xlabel('Epoch');\n",
        "  ax1.set_ylabel('Average MSE loss');\n",
        "\n",
        "  ax2 = fig.add_subplot(2,1,2)\n",
        "  plt2 = plt.plot(ep_range,valid_history,'ro-')\n",
        "  ax2.set_title('Average validation loss');\n",
        "  ax2.set_xlabel('Epoch');\n",
        "  ax2.set_ylabel('Average MSE loss');\n",
        "  plt.show()\n",
        "\n",
        "# Import progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Create the...\n",
        "# Model\n",
        "print('Generating model...')\n",
        "model = create_network(conv_layers,mlp_layers)\n",
        "\n",
        "# Try to attach the network to a GPU\n",
        "try:\n",
        "  model = model.cuda()\n",
        "  canUseGPU = True\n",
        "except:\n",
        "  print('Warning: The GPU has not been enabled. Training may take longer than expected.')\n",
        "  canUseGPU = False\n",
        "\n",
        "# Training dataset\n",
        "training_end = round(len(data_ages)*0.8)\n",
        "train_dataset = UTKFaceDataset(data_images[:,:,0:training_end], data_ages[0:training_end])\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset, shuffle=True, batch_size=batchsize)\n",
        "\n",
        "# Validation dataset\n",
        "validation_end = round(len(data_ages)*0.1)\n",
        "validation_dataset = UTKFaceDataset(data_images[:,:,training_end:training_end+validation_end], data_ages[training_end:training_end+validation_end])\n",
        "validation_data_loader = torch.utils.data.DataLoader(dataset=validation_dataset, shuffle=False, batch_size=batchsize)\n",
        "\n",
        "# Testing dataset\n",
        "testing_dataset = UTKFaceDataset(data_images[:,:,training_end+validation_end:-1], data_ages[training_end+validation_end:-1])\n",
        "testing_data_loader = torch.utils.data.DataLoader(dataset=testing_dataset, shuffle=False, batch_size=batchsize)\n",
        "\n",
        "# Define which loss function we will be using\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "# Specify the optimizer (or gradient descent algorithm)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Set up plots\n",
        "ep_range = np.zeros(1)\n",
        "\n",
        "# Run an initial pass to get base line values\n",
        "with torch.no_grad():\n",
        "  epoch_loss = 0\n",
        "  with tqdm(total=train_dataset.__len__(), desc=f'Epoch {0}/{number_of_epochs}', unit='img') as pbar:\n",
        "    for batch in train_data_loader:\n",
        "      # Move things to GPU\n",
        "      if canUseGPU:\n",
        "        batch['image'] = batch['image'].cuda()\n",
        "        batch['age'] = batch['age'].cuda()\n",
        "\n",
        "      # Perform forward pass\n",
        "      output = model.forward(batch['image'])\n",
        "      \n",
        "      # Calculate loss\n",
        "      loss_value = loss(output,batch['age'])\n",
        "      epoch_loss += loss_value.item()\n",
        "      pbar.set_postfix(**{'current loss': loss_value.item()})\n",
        "\n",
        "      # Update progress bar\n",
        "      pbar.update(batch['image'].shape[0])\n",
        "\n",
        "  train_history = np.array((epoch_loss/train_dataset.__len__())*batchsize)\n",
        "\n",
        "  with tqdm(total=validation_dataset.__len__(), desc=f'Epoch {0}/{number_of_epochs}', unit='img') as pbar:\n",
        "    epoch_loss = 0\n",
        "    for batch in validation_data_loader:\n",
        "      # Move things to GPU\n",
        "      if canUseGPU:\n",
        "        batch['image'] = batch['image'].cuda()\n",
        "        batch['age'] = batch['age'].cuda()\n",
        "\n",
        "      # Perform forward pass\n",
        "      output = model.forward(batch['image'])\n",
        "      \n",
        "      # Calculate loss\n",
        "      loss_value = loss(output,batch['age'])\n",
        "      epoch_loss += loss_value.item()\n",
        "      pbar.set_postfix(**{'current loss': loss_value.item()})\n",
        "\n",
        "      # Update progress bar\n",
        "      pbar.update(batch['image'].shape[0])\n",
        "\n",
        "  valid_history = np.array((epoch_loss/validation_dataset.__len__())*batchsize)\n",
        "\n",
        "# Train the network!\n",
        "start_time = time.time()\n",
        "for ep in range(number_of_epochs):\n",
        "  # Training loop\n",
        "  update_plots(ep_range,train_history,valid_history)\n",
        "  epoch_loss = 0\n",
        "\n",
        "  with tqdm(total=train_dataset.__len__(), desc=f'Epoch {ep + 1}/{number_of_epochs}', unit='img') as pbar:\n",
        "      for batch in train_data_loader:\n",
        "        # Move things to GPU\n",
        "        if canUseGPU:\n",
        "          batch['image'] = batch['image'].cuda()\n",
        "          batch['age'] = batch['age'].cuda()\n",
        "\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform forward pass\n",
        "        output = model.forward(batch['image'])\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss_value = loss(output,batch['age'])\n",
        "        epoch_loss += loss_value.item()\n",
        "        pbar.set_postfix(**{'current loss': loss_value.item()})\n",
        "\n",
        "        # Back-propogate\n",
        "        loss_value.backward()\n",
        "\n",
        "        # Gradient descent\n",
        "        optimizer.step()  \n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.update(batch['image'].shape[0])\n",
        "      pbar.set_postfix(**{'average training loss': (epoch_loss/train_dataset.__len__())*batchsize})\n",
        "\n",
        "      # Update training plot\n",
        "      ep_range = np.append(ep_range,ep+1)\n",
        "      train_history = np.append(train_history,(epoch_loss/train_dataset.__len__())*batchsize)\n",
        "      #update_plots(ep_range,train_history,valid_history)\n",
        "      \n",
        "  # Validation loop\n",
        "  epoch_loss = 0\n",
        "  with tqdm(total=validation_dataset.__len__(), desc=f'Validation', unit='img') as pbar:\n",
        "      for batch in validation_data_loader:\n",
        "        with torch.no_grad():\n",
        "          # Move things to GPU\n",
        "          if canUseGPU:\n",
        "            batch['image'] = batch['image'].cuda()\n",
        "            batch['age'] = batch['age'].cuda()\n",
        "\n",
        "          # Perform forward pass\n",
        "          output = model.forward(batch['image'])\n",
        "          \n",
        "          # Calculate loss\n",
        "          loss_value = loss(output,batch['age'])\n",
        "          epoch_loss += loss_value.item()\n",
        "          pbar.set_postfix(**{'current loss': loss_value.item()})\n",
        "          \n",
        "          # Update progress bar\n",
        "          pbar.update(batch['image'].shape[0])\n",
        "      pbar.set_postfix(**{'average validation loss': (epoch_loss/validation_dataset.__len__())*batchsize}) \n",
        "      \n",
        "      # Update validation plot\n",
        "      valid_history = np.append(valid_history,(epoch_loss/train_dataset.__len__())*batchsize)\n",
        "      update_plots(ep_range,train_history,valid_history)\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = (end_time-start_time)/60\n",
        "print('The training took ' + str(round((end_time-start_time)/60,2)) + ' minutes to complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RXBf3KMK_VK"
      },
      "source": [
        "### Predicting the age from the testing set\n",
        "---\n",
        "##### In the following code chunk, the model that was just trained is used to predict the age of the _testing_ portion of the dataset.\n",
        "##### The text output from the following code chunk specifies the average prediction error and how long it takes the network to predict the age of 10 images. You should compare these values to how well you did in the previous notebook at predicting ages. _(Keep in mind that the time the network takes to predict the age is outputted in milliseconds)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIP8iau9vqtH",
        "cellView": "form"
      },
      "source": [
        "#@title --- Hidden code (double-click to show code) ---\n",
        "# Testing set\n",
        "model.eval()\n",
        "\n",
        "epoch_loss = 0\n",
        "with tqdm(total=testing_dataset.__len__(), desc=f'Testing', unit='img') as pbar:\n",
        "    for batch in testing_data_loader:\n",
        "      with torch.no_grad():\n",
        "        # Move things to GPU\n",
        "        if canUseGPU:\n",
        "          batch['image'] = batch['image'].cuda()\n",
        "          batch['age'] = batch['age'].cuda()\n",
        "\n",
        "        # Perform forward pass\n",
        "        output = model.forward(batch['image'])\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss_value = loss(output,batch['age'])\n",
        "        epoch_loss += loss_value.item()\n",
        "        pbar.set_postfix(**{'current loss': loss_value.item()})\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.update(batch['image'].shape[0])\n",
        "    pbar.set_postfix(**{'average testing loss': (epoch_loss/testing_dataset.__len__())}) \n",
        "\n",
        "# Time 10 images\n",
        "start_time = time.time()\n",
        "output = model.forward(batch['image'])\n",
        "end_time = time.time()\n",
        "prediction_error = (epoch_loss/testing_dataset.__len__())**0.5\n",
        "\n",
        "# Print out some stats\n",
        "print('Your final average testing loss is: ' + str(epoch_loss/testing_dataset.__len__()))\n",
        "print('Your network has an average prediction error of ' + str(round(prediction_error,2))  + ' years.')\n",
        "print('The model takes ' + str(round((end_time-start_time)*1000,2)) + ' milliseconds to predict the age of 10 images.')\n",
        "print('Here are some images and their estimated age:')\n",
        "\n",
        "# Get a random set of 15 images\n",
        "random_test_ind = np.random.randint(0,testing_dataset.__len__(),15)\n",
        "\n",
        "# Display the images\n",
        "fig = plt.figure(figsize=(23,23))\n",
        "for i in range(15):\n",
        "  with torch.no_grad():\n",
        "    batch = testing_dataset.__getitem__(random_test_ind[i])\n",
        "\n",
        "    # Move things to GPU\n",
        "    if canUseGPU:\n",
        "      batch['image'] = batch['image'].cuda()\n",
        "      batch['age'] = batch['age'].cuda()\n",
        "\n",
        "    # Perform forward pass\n",
        "    output = model.forward(batch['image'].unsqueeze(0)) \n",
        "    \n",
        "  # Show the image\n",
        "  fig.add_subplot(3,5,i+1)\n",
        "  plt.imshow(batch['image'].squeeze(0).cpu().detach().numpy(), cmap='gray')\n",
        "  plt.gca().set_title(\"Predicted: \" + str(np.round(output[0,0].cpu().detach().numpy())) + \" | Actual: \" + str(batch['age'][0].cpu().detach().numpy()))\n",
        "plt.gcf().subplots_adjust(bottom=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oa4MidCOtNr"
      },
      "source": [
        "# Generate and submit report for competition\n",
        "---\n",
        "##### To submit your network for the competition, run the following two code chunks. You will have to use the output from the first code chunk to fill in the form that is outputted from the second code chunk. When you are ready, press submit below the submission form. You will get a message reading that the script is complete.\n",
        "##### You are welcome to submit as many times as you would like!\n",
        "#####**Note: Please fill in the form _exactly_ as it is outputted from the first code chunk. Submissions that are not filled in correctly will _not_ be considered!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btKPSUhWBDxA",
        "cellView": "form"
      },
      "source": [
        "#@title --- Hidden code (double-click to show code) ---\n",
        "count = 0\n",
        "filters = []\n",
        "filter_size = []\n",
        "for i in range(conv_layers.n_rows):\n",
        "  filters.append(conv_layers.children[count].value)\n",
        "  filter_size.append(conv_layers.children[count+1].value)\n",
        "  count += 2\n",
        "\n",
        "print(\"Number of convolution filters: \" + str(len(filters)))\n",
        "print(\"Number of filters in convolution layers: \" + str(filters))\n",
        "print(\"Size of filters: \" + str(filter_size))\n",
        "\n",
        "connections = []\n",
        "for i in range(mlp_layers.n_rows):\n",
        "  connections.append(mlp_layers.children[i].value)\n",
        "\n",
        "print(\"Number of connections in MLP: \" + str(connections))\n",
        "print(\"Number of epochs: \" + str(number_of_epochs))\n",
        "print(\"Time it took to train: \" + str(round(training_time,5)))\n",
        "print(\"Prediction error: \" + str(round(prediction_error,5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjyAPsiZbmLc",
        "cellView": "form"
      },
      "source": [
        "#@title --- Hidden code (double-click to show code) ---\n",
        "%%html\n",
        "<!doctype html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <meta name=\"description\" content=\"Submission form\">\n",
        "  <title>Submission Form</title>\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  <h2 class=\"content-head is-center\"> \n",
        "    <p> CNN competition submission form. </p> \n",
        "    Please fill in this form by copying the information from the previous code chunk output.\n",
        "  </h2>\n",
        "\n",
        "<!-- START HERE -->\n",
        "   <link rel=\"stylesheet\" href=\"https://unpkg.com/purecss@1.0.0/build/pure-min.css\">\n",
        "   <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css\">\n",
        "   <!-- Style The Contact Form How Ever You Prefer -->\n",
        "   <link rel=\"stylesheet\" href=\"style.css\">\n",
        "\n",
        "  <form class=\"gform pure-form pure-form-stacked\" method=\"POST\" data-email=\"example@email.net\"\n",
        "  action=\"https://script.google.com/macros/s/AKfycbxIIZDYlT-PSTYeWHCnUJT0ZlrrNzbzXnC3pZFg-rrMeAYnNFvS/exec\">\n",
        "    <!-- change the form action to your script url -->\n",
        "\n",
        "    <div class=\"form-elements\">\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"name\">Name:</label>\n",
        "        <input id=\"name\" name=\"Name\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"number_of_conv_layers\">Number of convolution layers:</label>\n",
        "        <input id=\"number_of_conv_layers\" name=\"Number of convolution layers\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"number_of_conv_filters\">Number of filters in convolution layers:</label>\n",
        "        <input id=\"number_of_conv_filters\" name=\"Number of filters per layer\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"filter_size\">Size of filters:</label>\n",
        "        <input id=\"filter_size\" name=\"Size of filters\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"number_of_connections\">Number of connections in MLP:</label>\n",
        "        <input id=\"number_of_connections\" name=\"Number of MLP connections\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"number_of_epochs\">Number of epochs:</label>\n",
        "        <input id=\"number_of_epochs\" name=\"Number of training epochs\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"training_time\">Time it took to train:</label>\n",
        "        <input id=\"training_time\" name=\"Training time [minutes]\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group\">\n",
        "        <label for=\"prediction_error\">Prediction error:</label>\n",
        "        <input id=\"prediction_error\" name=\"Prediction error [years]\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <fieldset class=\"pure-group honeypot-field\">\n",
        "        <label for=\"honeypot\">Keep this field blank</label>\n",
        "        <input id=\"honeypot\" type=\"text\" name=\"honeypot\" value=\"\" />\n",
        "      </fieldset>\n",
        "\n",
        "      <button class=\"button-success pure-button button-xlarge\">\n",
        "        <i class=\"fa fa-paper-plane\"></i>&nbsp;Send</button>\n",
        "    </div>\n",
        "\n",
        "  </form>\n",
        "<!-- END -->\n",
        "\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOrm7r3toat8"
      },
      "source": [
        "# How did you do?\n",
        "---\n",
        "##### You should be able to see you network results on the leaderboard [here](https://docs.google.com/spreadsheets/d/e/2PACX-1vQUS48na12B9JbZ2p7IjWqk4oQEKqT0ljPpVdD8FMFN8BeN7HJutVN_Mo3_AbX-I7w8xVFKgxDfC0BR/pubhtml)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08iydcfdhNMA"
      },
      "source": [
        "# Ready for the next notebook?\n",
        "---\n",
        "##### You can click [here](https://colab.research.google.com/github/aewoessn/outreach-program-2021/blob/main/notebooks/4.3_EndOfDay2.ipynb) to take you to the next notebook."
      ]
    }
  ]
}